<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>8824b6f3e71c41ca86d2c3e710cbb9c4</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell code" data-execution_count="1" id="SMUf-sJEMOE0">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.datasets</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.utils.data</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plot</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> perf_counter</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="2"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="z2V7DY7uNZMc" data-outputId="24c52147-7909-4fdc-e254-e2958e1e63cc">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>dir_name <span class="op">=</span> os.getcwd()</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_images(images, title):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    num_showed_imgs_x <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    num_showed_imgs_y <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    figsize <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plot.subplots(num_showed_imgs_y, num_showed_imgs_x, figsize <span class="op">=</span> figsize)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    fig.suptitle(title)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    plot.setp(plot.gcf().get_axes(), xticks <span class="op">=</span> [], yticks <span class="op">=</span> [])</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes.flat):</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> images[i][<span class="dv">0</span>].numpy().transpose(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>).squeeze(axis <span class="op">=</span> <span class="dv">2</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        ax.imshow(img, cmap <span class="op">=</span> <span class="st">&#39;gray&#39;</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> torchvision.datasets.MNIST(</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    root <span class="op">=</span> dir_name, train <span class="op">=</span> <span class="va">True</span>, download <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> torchvision.transforms.ToTensor()</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> torchvision.datasets.MNIST(</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    root <span class="op">=</span> dir_name, train <span class="op">=</span> <span class="va">False</span>, download <span class="op">=</span> <span class="va">True</span>,</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> torchvision.transforms.ToTensor()</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Number of train samples: </span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(<span class="bu">len</span>(train_dataset)))</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>show_images(train_dataset, <span class="st">&#39;Train samples&#39;</span>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Number of test samples: </span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(<span class="bu">len</span>(test_dataset)))</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>show_images(test_dataset, <span class="st">&#39;Test samples&#39;</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>train_data_loader <span class="op">=</span> torch.utils.data.DataLoader(</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    train_dataset, batch_size <span class="op">=</span> batch_size, shuffle <span class="op">=</span> <span class="va">True</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>test_data_loader <span class="op">=</span> torch.utils.data.DataLoader(</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    test_dataset, batch_size <span class="op">=</span> batch_size, shuffle <span class="op">=</span> <span class="va">False</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/MNIST/raw/train-images-idx3-ubyte.gz
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 9912422/9912422 [00:00&lt;00:00, 58834358.46it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Extracting /content/MNIST/raw/train-images-idx3-ubyte.gz to /content/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/MNIST/raw/train-labels-idx1-ubyte.gz
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 28881/28881 [00:00&lt;00:00, 42955919.80it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Extracting /content/MNIST/raw/train-labels-idx1-ubyte.gz to /content/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/MNIST/raw/t10k-images-idx3-ubyte.gz
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 1648877/1648877 [00:00&lt;00:00, 22394861.01it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Extracting /content/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/MNIST/raw/t10k-labels-idx1-ubyte.gz
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 4542/4542 [00:00&lt;00:00, 11781403.07it/s]</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Extracting /content/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/MNIST/raw

</code></pre>
</div>
<div class="output stream stderr">
<pre><code>
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Number of train samples: 60000
Number of test samples: 10000
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_8b534592a0434af8bcd1410453700179/86e1f7b358e872f13c542881d679e821992c2f68.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_8b534592a0434af8bcd1410453700179/55b786140ffb3841f02d3a2404920dd440947936.png" /></p>
</div>
</div>
<div class="cell code" data-execution_count="3"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="arSdrOQUR00V" data-outputId="9162a6a7-ad81-4c7f-86ec-3d0a9d4b6912">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Обучающая выборка: &quot;</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_dataset.data.shape)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(train_dataset.targets.shape)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Тестовая выборка: &quot;</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_dataset.data.shape)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(test_dataset.targets.shape)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучающая выборка: 
torch.Size([60000, 28, 28])
torch.Size([60000])
Тестовая выборка: 
torch.Size([10000, 28, 28])
torch.Size([10000])
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="11" id="PVA9DWaETAm3">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>image_resolution <span class="op">=</span> <span class="dv">28</span> <span class="op">*</span> <span class="dv">28</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>hidden_layers <span class="op">=</span> <span class="dv">300</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">20</span></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="6"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="iH5aDJEATBcI" data-outputId="f10c49ea-d2ea-44ff-ccbb-337a75cb2175">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> init_weights(model):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(model)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">type</span>(model) <span class="op">==</span> torch.nn.Linear:</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    torch.nn.init.xavier_uniform_(model.weight)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(model.weight)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(image_resolution, hidden_layers),</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    torch.nn.ReLU(),</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    torch.nn.Linear(hidden_layers, num_classes),</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>net</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>net.<span class="bu">apply</span>(init_weights)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Linear(in_features=784, out_features=300, bias=True)
Parameter containing:
tensor([[-0.0415, -0.0655, -0.0541,  ...,  0.0627,  0.0473, -0.0624],
        [-0.0721,  0.0486, -0.0222,  ...,  0.0544,  0.0621, -0.0283],
        [-0.0247,  0.0096, -0.0419,  ..., -0.0537,  0.0103, -0.0681],
        ...,
        [-0.0091,  0.0042,  0.0388,  ...,  0.0074,  0.0253, -0.0207],
        [ 0.0293,  0.0328, -0.0070,  ...,  0.0672,  0.0500, -0.0655],
        [-0.0133, -0.0264,  0.0533,  ..., -0.0407, -0.0507, -0.0591]],
       requires_grad=True)
ReLU()
Linear(in_features=300, out_features=10, bias=True)
Parameter containing:
tensor([[-0.0901, -0.0823, -0.0093,  ...,  0.0412,  0.1189,  0.0428],
        [ 0.0523, -0.0674, -0.0611,  ...,  0.0454, -0.1139,  0.1126],
        [ 0.0891, -0.0473, -0.1263,  ...,  0.0374,  0.0330, -0.1371],
        ...,
        [ 0.0898, -0.0659, -0.0498,  ...,  0.1018, -0.0418, -0.0458],
        [-0.0232, -0.1350,  0.0792,  ..., -0.0333, -0.0822,  0.0560],
        [-0.0091,  0.0762, -0.0420,  ...,  0.1195,  0.1030,  0.0279]],
       requires_grad=True)
Sequential(
  (0): Linear(in_features=784, out_features=300, bias=True)
  (1): ReLU()
  (2): Linear(in_features=300, out_features=10, bias=True)
)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="6">
<pre><code>Sequential(
  (0): Linear(in_features=784, out_features=300, bias=True)
  (1): ReLU()
  (2): Linear(in_features=300, out_features=10, bias=True)
)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="7"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="d56_Cm9rXrpl" data-outputId="e1423f76-0db7-4e92-9fe6-908e23b9bc1d">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda:0&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>net.to(device)</span></code></pre></div>
<div class="output execute_result" data-execution_count="7">
<pre><code>Sequential(
  (0): Linear(in_features=784, out_features=300, bias=True)
  (1): ReLU()
  (2): Linear(in_features=300, out_features=10, bias=True)
)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="8" id="0TBRdLMVXv8i">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> torch.nn.CrossEntropyLoss()</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(net.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_accuracy(data_loader, model):</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    tp <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> images, labels <span class="kw">in</span> data_loader:</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>            images <span class="op">=</span> images.reshape(<span class="op">-</span><span class="dv">1</span>, image_resolution).to(device)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(images)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data.to(device), <span class="dv">1</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>            predicted <span class="op">=</span> predicted.to(device)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>            n <span class="op">+=</span> labels.size(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>            tp <span class="op">+=</span> (predicted <span class="op">==</span> labels).<span class="bu">sum</span>()</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tp <span class="op">/</span> n</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="usxkzmYhX2AI" data-outputId="b8c11ac3-9d61-4b1a-998f-ecf24abbeb1a">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    time <span class="op">=</span> perf_counter()</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (images, labels) <span class="kw">in</span> <span class="bu">enumerate</span>(train_data_loader):</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        images <span class="op">=</span> images.view(<span class="op">-</span><span class="dv">1</span>, image_resolution).requires_grad_().to(device)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> labels.to(device)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> net(images)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> loss_fn(outputs, labels)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>        loss.backward()</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    time <span class="op">=</span> perf_counter() <span class="op">-</span> time</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Epoch[</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">]: accuracy = </span><span class="sc">{</span>get_accuracy(train_data_loader, net)<span class="sc">}</span><span class="ss">, time = </span><span class="sc">{</span>time<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Test accuracy: </span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(get_accuracy(test_data_loader, net)))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch[0]: accuracy = 0.9936000108718872, time = 15.797685626000202
Epoch[1]: accuracy = 0.995283305644989, time = 13.590039825000076
Epoch[2]: accuracy = 0.9961833357810974, time = 13.860654071999761
Epoch[3]: accuracy = 0.9976500272750854, time = 12.924827233000087
Epoch[4]: accuracy = 0.9983333349227905, time = 13.671678581999913
Epoch[5]: accuracy = 0.9980833530426025, time = 13.225376457000038
Epoch[6]: accuracy = 0.9989500045776367, time = 13.87565093100011
Epoch[7]: accuracy = 0.9992833137512207, time = 13.041907138999704
Epoch[8]: accuracy = 0.9995666742324829, time = 12.9904238969998
Epoch[9]: accuracy = 0.999666690826416, time = 13.030434850999882
Epoch[10]: accuracy = 0.9998166561126709, time = 13.368508442999882
Epoch[11]: accuracy = 0.9997666478157043, time = 13.593622260999837
Epoch[12]: accuracy = 0.9998666644096375, time = 13.332706292999774
Epoch[13]: accuracy = 0.9998666644096375, time = 13.171925479000038
Epoch[14]: accuracy = 0.9999499917030334, time = 13.372328966000168
Epoch[15]: accuracy = 0.9999833106994629, time = 14.194940927999596
Epoch[16]: accuracy = 0.9999499917030334, time = 13.84411709599999
Epoch[17]: accuracy = 0.9999333620071411, time = 14.174224947999846
Epoch[18]: accuracy = 0.9999833106994629, time = 13.314917110999886
Epoch[19]: accuracy = 1.0, time = 14.774359946000004
Test accuracy: 0.982699990272522
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="16"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="ZvjJeCd1YE3J" data-outputId="2116cbd8-d9d5-4570-cf75-9407d7e5e5f4">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>weights_Linear1 <span class="op">=</span> torch.zeros([hidden_layers, image_resolution], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>weights_Linear1.shape</span></code></pre></div>
<div class="output execute_result" data-execution_count="16">
<pre><code>torch.Size([300, 784])</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="17" id="jaldpO5nYWnU">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Model:</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, image_resolution, num_classes, hidden_layers, batch_size, learning_rate):</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.image_resolution <span class="op">=</span> image_resolution</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.num_classes <span class="op">=</span> num_classes</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.hidden_layers <span class="op">=</span> hidden_layers</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.batch_size <span class="op">=</span> batch_size</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.learning_rate <span class="op">=</span> learning_rate</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.weights_Linear1 <span class="op">=</span> torch.zeros([<span class="va">self</span>.hidden_layers, <span class="va">self</span>.image_resolution], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.bias_Linear1 <span class="op">=</span> torch.zeros([<span class="va">self</span>.hidden_layers, <span class="dv">1</span>], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.weights_Linear2 <span class="op">=</span> torch.zeros([<span class="va">self</span>.num_classes, <span class="va">self</span>.hidden_layers], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.bias_Linear2 <span class="op">=</span> torch.zeros([<span class="va">self</span>.num_classes, <span class="dv">1</span>], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.probs <span class="op">=</span> <span class="va">None</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>      <span class="va">self</span>.init_weights()</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> init_weights(<span class="va">self</span>):</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>      torch.nn.init.xavier_uniform_(<span class="va">self</span>.weights_Linear1)</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>      torch.nn.init.zeros_(<span class="va">self</span>.bias_Linear1)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>      torch.nn.init.xavier_uniform_(<span class="va">self</span>.weights_Linear2)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>      torch.nn.init.zeros_(<span class="va">self</span>.bias_Linear2)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, images):</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.forward(images)</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, images: torch.Tensor):</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear1 <span class="op">=</span> (images <span class="op">@</span> <span class="va">self</span>.weights_Linear1.transpose(<span class="dv">0</span>, <span class="dv">1</span>).to(device)) <span class="op">+</span> <span class="va">self</span>.bias_Linear1.transpose(<span class="dv">0</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu <span class="op">=</span> torch.relu(<span class="va">self</span>.linear1)</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear2 <span class="op">=</span> (<span class="va">self</span>.relu <span class="op">@</span> <span class="va">self</span>.weights_Linear2.transpose(<span class="dv">0</span>, <span class="dv">1</span>).to(device)) <span class="op">+</span> <span class="va">self</span>.bias_Linear2.transpose(<span class="dv">0</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.probs <span class="op">=</span> torch.softmax(<span class="va">self</span>.linear2, <span class="dv">1</span>)</span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.<span class="bu">input</span> <span class="op">=</span> images</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.linear2</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> backward(<span class="va">self</span>, labels):</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights_Linear1 <span class="op">=</span> <span class="va">self</span>.weights_Linear1.to(device)</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights_Linear2 <span class="op">=</span> <span class="va">self</span>.weights_Linear2.to(device)</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias_Linear1 <span class="op">=</span> <span class="va">self</span>.bias_Linear1.to(device)</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias_Linear2 <span class="op">=</span> <span class="va">self</span>.bias_Linear2.to(device)</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>        new_labels <span class="op">=</span> torch.zeros_like(<span class="va">self</span>.probs)</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(labels.shape[<span class="dv">0</span>]):</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>            new_labels[i, labels[i]] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> (<span class="va">self</span>.probs <span class="op">-</span> new_labels) <span class="op">/</span> labels.shape[<span class="dv">0</span>]</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>        dw2 <span class="op">=</span> loss.transpose(<span class="dv">0</span>, <span class="dv">1</span>).to(device) <span class="op">@</span> <span class="va">self</span>.relu</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>        db2 <span class="op">=</span> loss.<span class="bu">sum</span>(<span class="dv">0</span>).unsqueeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>        loss1 <span class="op">=</span> torch.mul(loss.to(device) <span class="op">@</span> <span class="va">self</span>.weights_Linear2.to(device), <span class="va">self</span>.linear1 <span class="op">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>        dw1 <span class="op">=</span> loss1.transpose(<span class="dv">0</span>, <span class="dv">1</span>).to(device) <span class="op">@</span> <span class="va">self</span>.<span class="bu">input</span></span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a>        db1 <span class="op">=</span> loss1.<span class="bu">sum</span>(<span class="dv">0</span>).unsqueeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights_Linear1 <span class="op">-=</span> learning_rate <span class="op">*</span> dw1</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.weights_Linear2 <span class="op">-=</span> learning_rate <span class="op">*</span> dw2</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias_Linear1 <span class="op">-=</span> learning_rate <span class="op">*</span> db1</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bias_Linear2 <span class="op">-=</span> learning_rate <span class="op">*</span> db2</span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
</div>
<div class="cell code" data-execution_count="18"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="IJ4CigT_YXPs" data-outputId="c73e80bb-4fa6-423f-901d-3886d417cc73">
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model(image_resolution, num_classes, hidden_layers, batch_size, learning_rate)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">20</span>):</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    time <span class="op">=</span> perf_counter()</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> images, labels <span class="kw">in</span> train_data_loader:</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        images <span class="op">=</span> images.view(<span class="op">-</span><span class="dv">1</span>, image_resolution).to(device)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        labels <span class="op">=</span> labels.to(device)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        model.forward(images)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>        model.backward(labels)</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    time <span class="op">=</span> perf_counter() <span class="op">-</span> time</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&#39;Epoch[</span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">]: accuracy = </span><span class="sc">{</span>get_accuracy(train_data_loader, model)<span class="sc">}</span><span class="ss">, time = </span><span class="sc">{</span>time<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Test accuracy: </span><span class="sc">{}</span><span class="st">&#39;</span>.<span class="bu">format</span>(get_accuracy(test_data_loader, model)))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch[0]: accuracy = 0.9505333304405212, time = 12.512297825000132
Epoch[1]: accuracy = 0.9727833271026611, time = 12.452390767999987
Epoch[2]: accuracy = 0.9798833131790161, time = 12.513442760999624
Epoch[3]: accuracy = 0.9812666773796082, time = 12.36207946200011
Epoch[4]: accuracy = 0.987416684627533, time = 12.346426887999769
Epoch[5]: accuracy = 0.9894833564758301, time = 12.357165778999843
Epoch[6]: accuracy = 0.9927666783332825, time = 12.254212302999804
Epoch[7]: accuracy = 0.9914500117301941, time = 12.266370755000025
Epoch[8]: accuracy = 0.995283305644989, time = 12.259858487000201
Epoch[9]: accuracy = 0.9955666661262512, time = 12.337172580000242
Epoch[10]: accuracy = 0.9965833425521851, time = 12.326125821000005
Epoch[11]: accuracy = 0.9976000189781189, time = 12.35539165299997
Epoch[12]: accuracy = 0.9986166954040527, time = 12.339567471999999
Epoch[13]: accuracy = 0.9986666440963745, time = 12.338284455000576
Epoch[14]: accuracy = 0.9990500211715698, time = 12.256432392000534
Epoch[15]: accuracy = 0.9994999766349792, time = 11.937451709000015
Epoch[16]: accuracy = 0.9996166825294495, time = 12.155183486999704
Epoch[17]: accuracy = 0.9995999932289124, time = 12.119254100000035
Epoch[18]: accuracy = 0.999750018119812, time = 12.094498356000258
Epoch[19]: accuracy = 0.9998499751091003, time = 12.14047572399977
Test accuracy: 0.9832000136375427
</code></pre>
</div>
</div>
</body>
</html>
